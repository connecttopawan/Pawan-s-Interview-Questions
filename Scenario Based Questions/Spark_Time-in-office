Ques: Below is the in-out time of employees of an office. Find total time of employee in the office.
	Eid, TS, Event
	1,2020-12-30T09:00:00, IN
	1,2020-12-30T13:00:00, OUT
	1,2020-12-30T14:00:00, IN
	1,2020-12-30T17:00:00, OUT
	1,2020-12-30T17:30:00, IN
	1,2020-12-30T20:00:00, OUT
	2,2020-12-30T10:30:00, IN
	2,2020-12-30T15:00:00, OUT
	2,2020-12-30T16:30:00, IN
	2,2020-12-30T21:30:00, IN
	2,2020-12-30T22:30:00, OUT
	1,2020-12-31T09:00:00, IN
	1,2020-12-31T13:00:00, OUT
	1,2020-12-31T14:00:00, IN
	1,2020-12-31T17:00:00, OUT
	1,2020-12-31T17:30:00, IN
	1,2020-12-31T20:00:00, OUT
	2,2020-12-31T10:30:00, IN
	2,2020-12-31T15:00:00, OUT
	2,2020-12-31T16:30:00, IN
	2,2020-12-31T21:30:00, IN
	2,2020-12-31T23:30:00, OUT
Sol:
	df = spark.read.csv('lag_lead.csv',inferSchema=True,header=True)
	df = df.withColumn('r_Date',col('ts').cast(DateType()))\
       .withColumn('new_ts',col('ts').cast('long'))
	from pyspark.sql.window import *
	df = df.withColumn('leading',(lead('new_ts').over(Window.partitionBy('eid','r_Date').orderBy(col('ts')))-col('new_ts')))
	df = df.withColumn('leading',when(col('event')=='OUT',col('leading')*-1).otherwise('leading'))
	df=df.groupBy('eid','event','ts','r_Date')\
     .agg(sum('leading').alias('sum_leading'))\
     .select('eid', 'event', 'ts', 'r_date', lit(col('sum_leading')/3600).alias('sum_leading'))
    
	df = df.withColumn('find_total',(col('ts').cast('long')-lag(col('ts').cast('long'))
                                .over(Window.partitionBy('eid','r_date').orderBy('ts')))/3600)\
       .fillna(0,subset=('find_total','sum_leading'))
    df = df.withColumn('final_total_hrs',col('find_total')+col('sum_leading'))
	df.groupBy('eid','r_date').agg(sum('final_total_hrs').alias('spent_hrs')).show()